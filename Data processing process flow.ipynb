{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d1e8a7-10c6-4f76-9d47-3e5ac4bf808e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. PATH CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f7d6e8-406e-4e44-857b-9888f48d0b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Working Directory: C:\\Users\\iurie\\3. Tableau Projects\\01. SOC-Analyst-Job-Market-Analysis\\2. Data_Processing_Process\n",
      "üìÇ Raw Data Directory detected at: C:\\Users\\iurie\\3. Tableau Projects\\01. SOC-Analyst-Job-Market-Analysis\\1. Raw_Data_Set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. PATH CONFIGURATION ---\n",
    "\n",
    "# Current working directory (where this Notebook is located)\n",
    "CURRENT_DIR = os.getcwd()\n",
    "\n",
    "# Move one level up (..) to access the Raw_Data_Set folder\n",
    "RAW_DATA_DIR = os.path.join(CURRENT_DIR, '..', '1. Raw_Data_Set')\n",
    "\n",
    "# Define exact paths for data sources\n",
    "PATH_LINKEDIN = os.path.join(RAW_DATA_DIR, 'LinkedIn')\n",
    "PATH_GLASSDOOR = os.path.join(RAW_DATA_DIR, 'GlassDoor')\n",
    "\n",
    "# Configuration files (located in the same folder as this Notebook)\n",
    "FILE_ROLES = 'SOC_Analyst_Roles.json'\n",
    "FILE_SKILLS = 'Skills.json'\n",
    "FILE_LOCATIONS_FIX = 'Locations.json'\n",
    "\n",
    "# Final output file for Tableau\n",
    "FINAL_OUTPUT = 'SOC_Analyst_Master_Dataset.json'\n",
    "\n",
    "print(f\"üìÇ Working Directory: {CURRENT_DIR}\")\n",
    "print(f\"üìÇ Raw Data Directory detected at: {os.path.abspath(RAW_DATA_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b486da3-5af1-4c1b-bae2-22c83477baec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. LOAD CONFIGURATION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47cc9a95-284e-4dac-bd40-f87fb45b4faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration files (Roles, Skills, Locations) loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. LOAD CONFIGURATION FILES ---\n",
    "\n",
    "try:\n",
    "    # Load Roles Definition\n",
    "    with open(FILE_ROLES, 'r', encoding='utf-8') as f:\n",
    "        roles_data = json.load(f)\n",
    "        # Handle cases where data is nested under \"all roles SOC\"\n",
    "        ROLES_DEF = roles_data.get(\"all roles SOC\", roles_data)\n",
    "\n",
    "    # Load Skills Definition\n",
    "    with open(FILE_SKILLS, 'r', encoding='utf-8') as f:\n",
    "        skills_data = json.load(f)\n",
    "        SKILLS_DEF = skills_data.get(\"Skills\", skills_data)\n",
    "\n",
    "    # Load Location Fixes (Mapping)\n",
    "    with open(FILE_LOCATIONS_FIX, 'r', encoding='utf-8') as f:\n",
    "        loc_list = json.load(f)\n",
    "        # Convert list to dictionary for O(1) lookup speed using 'location' as key\n",
    "        LOC_FIX_MAP = {item['location']: item for item in loc_list}\n",
    "\n",
    "    print(\"‚úÖ Configuration files (Roles, Skills, Locations) loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå ERROR: Configuration file not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå UNEXPECTED ERROR while reading config: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6643c-a902-4bbd-a2e7-1796452a84d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. DATA NORMALIZATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effe20f2-69e7-42f4-8f02-4439dfbe2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DATA NORMALIZATION FUNCTION (FIXED: Added missing fields) ---\n",
    "\n",
    "def normalize_job_structure(job_data, source_name):\n",
    "    \"\"\"\n",
    "    Accepts a raw job object (dict) and returns a standardized dictionary.\n",
    "    Includes experienceLevel and companyUrl to match the old dataset structure.\n",
    "    \"\"\"\n",
    "    normalized = {}\n",
    "    \n",
    "    if source_name == \"LinkedIn\":\n",
    "        normalized = {\n",
    "            \"title\": job_data.get(\"title\"),\n",
    "            \"companyName\": job_data.get(\"companyName\"),\n",
    "            \"location\": job_data.get(\"location\"),\n",
    "            \"jobUrl\": job_data.get(\"jobUrl\"),\n",
    "            \"contractType\": job_data.get(\"contractType\"),\n",
    "            \"sector\": job_data.get(\"sector\"),\n",
    "            # C√ÇMPURI ADƒÇUGATE:\n",
    "            \"experienceLevel\": job_data.get(\"experienceLevel\"),\n",
    "            \"companyUrl\": job_data.get(\"companyUrl\"),\n",
    "            \n",
    "            \"description\": job_data.get(\"description\"),\n",
    "            \"source\": \"LinkedIn\"\n",
    "        }\n",
    "    elif source_name == \"GlassDoor\":\n",
    "        # Glassdoor location cleaning\n",
    "        loc_obj = job_data.get(\"job_location\")\n",
    "        loc_str = \"\"\n",
    "        if isinstance(loc_obj, dict):\n",
    "            parts = [p for p in [loc_obj.get(\"city\"), loc_obj.get(\"country\")] if p]\n",
    "            loc_str = \", \".join(parts)\n",
    "        elif isinstance(loc_obj, str):\n",
    "            loc_str = loc_obj\n",
    "\n",
    "        normalized = {\n",
    "            \"title\": job_data.get(\"job_title\"),\n",
    "            \"companyName\": job_data.get(\"company_name\"),\n",
    "            \"location\": loc_str,\n",
    "            \"jobUrl\": job_data.get(\"job_url\"),\n",
    "            \"contractType\": job_data.get(\"job_job_types\"),\n",
    "            \"sector\": job_data.get(\"job_industry\"),\n",
    "            # C√ÇMPURI ADƒÇUGATE (Glassdoor le nume»ôte altfel uneori, folosim get safe):\n",
    "            \"experienceLevel\": job_data.get(\"job_levels\"), \n",
    "            \"companyUrl\": job_data.get(\"company_url\"), \n",
    "            \n",
    "            \"description\": job_data.get(\"job_description\"),\n",
    "            \"source\": \"GlassDoor\"\n",
    "        }\n",
    "    \n",
    "    # Basic string cleaning\n",
    "    if normalized['location']:\n",
    "        normalized['location'] = normalized['location'].strip()\n",
    "        \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff0434-3b0e-41a0-9085-57d1f1b90dfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. DATA PROCESSING PIPELINE (ETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62759c7c-9904-43a2-a2bf-1bc1485e7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Data Processing Pipeline...\n",
      "üìÇ Found 41 JSON files in total.\n",
      "üìä Total raw jobs extracted: 4076\n",
      "\n",
      "--- FINAL EXECUTION REPORT ---\n",
      "1. Total Jobs Scanned: 4076\n",
      "2. Excluded (Irrelevant): -1678\n",
      "3. Excluded (Duplicates): -61\n",
      "==========================================\n",
      "‚úÖ FINAL DATASET FOR TABLEAU: 2337 jobs\n"
     ]
    }
   ],
   "source": [
    "# --- 4. DATA PROCESSING PIPELINE (ETL) - ADVANCED LOCATION FIX ---\n",
    "\n",
    "all_jobs = []\n",
    "processed_jobs = []\n",
    "seen_ids = set() \n",
    "\n",
    "# Statistics\n",
    "stats = {\n",
    "    \"total_read\": 0,\n",
    "    \"excluded_filter\": 0,\n",
    "    \"excluded_duplicate\": 0,\n",
    "    \"final_count\": 0\n",
    "}\n",
    "\n",
    "# Keywords\n",
    "KEYWORDS_FILTER = [\"soc\", \"security operation\", \"incident response\", \"threat intelligence\", \"cyber defense\", \"siem\", \"blue team\"]\n",
    "\n",
    "# --- MAPARE MANUALƒÇ PENTRU ZONE METROPOLITANE (FIX PENTRU CELE 52 TƒÇRI) ---\n",
    "# Aici transformƒÉm \"Regiunile\" care apar ca »õƒÉri √Æn »öara corectƒÉ.\n",
    "REGION_TO_COUNTRY_MAP = {\n",
    "    \"Stuttgart Region\": \"Germany\",\n",
    "    \"Greater Milan Metropolitan Area\": \"Italy\",\n",
    "    \"Greater Hamburg Area\": \"Germany\",\n",
    "    \"Copenhagen Metropolitan Area\": \"Denmark\",\n",
    "    \"Timisoara Metropolitan Area\": \"Romania\",\n",
    "    \"Sofia Metropolitan Area\": \"Bulgaria\",\n",
    "    \"Lodz Metropolitan Area\": \"Poland\",\n",
    "    \"Katowice Metropolitan Area\": \"Poland\",\n",
    "    \"Greater Zaragoza Metropolitan Area\": \"Spain\",\n",
    "    \"Greater Turin Metropolitan Area\": \"Italy\",\n",
    "    \"Greater Toulouse Metropolitan Area\": \"France\",\n",
    "    \"Greater Lyon Area\": \"France\",\n",
    "    \"Greater Leipzig Area\": \"Germany\",\n",
    "    \"Greater Kiel Area\": \"Germany\",\n",
    "    \"Greater Helsingborg Metropolitan Area\": \"Sweden\",\n",
    "    \"Greater Granada Metropolitan Area\": \"Spain\",\n",
    "    \"Greater Bilbao Metropolitan Area\": \"Spain\",\n",
    "    \"Greater Vasteras Metropolitan Area\": \"Sweden\",\n",
    "    \"Greater Munchen Metropolitan Area\": \"Germany\",\n",
    "    \"Greater Paris Metropolitan Area\": \"France\",\n",
    "    \"Greater London\": \"United Kingdom\",\n",
    "    \"Randstad\": \"Netherlands\",\n",
    "    \"Ile-De-France\": \"France\"\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting Data Processing Pipeline...\")\n",
    "\n",
    "# --- STEP A: INGESTION ---\n",
    "files_list = []\n",
    "files_list.extend(glob.glob(os.path.join(PATH_LINKEDIN, \"*.json\")))\n",
    "files_list.extend(glob.glob(os.path.join(PATH_GLASSDOOR, \"*.json\")))\n",
    "\n",
    "print(f\"üìÇ Found {len(files_list)} JSON files in total.\")\n",
    "\n",
    "for file in files_list:\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            source = \"LinkedIn\" if \"LinkedIn\" in file else \"GlassDoor\"\n",
    "            if isinstance(data, list):\n",
    "                for job in data:\n",
    "                    all_jobs.append(normalize_job_structure(job, source))\n",
    "            elif isinstance(data, dict):\n",
    "                 all_jobs.append(normalize_job_structure(data, source))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading file {os.path.basename(file)}: {e}\")\n",
    "\n",
    "stats[\"total_read\"] = len(all_jobs)\n",
    "print(f\"üìä Total raw jobs extracted: {stats['total_read']}\")\n",
    "\n",
    "\n",
    "# --- STEP B: TRANSFORMATION ---\n",
    "\n",
    "for job in all_jobs:\n",
    "    title = str(job.get(\"title\", \"\")).lower()\n",
    "    desc = str(job.get(\"description\", \"\")).lower()\n",
    "    \n",
    "    # 1. FILTER\n",
    "    is_relevant = any(kw in title for kw in KEYWORDS_FILTER) or any(kw in desc for kw in KEYWORDS_FILTER)\n",
    "    if not is_relevant:\n",
    "        stats[\"excluded_filter\"] += 1\n",
    "        continue \n",
    "\n",
    "    # 2. DEDUPLICATION\n",
    "    comp = str(job.get(\"companyName\", \"\")).lower().replace(\" \", \"\").replace(\",\", \"\")\n",
    "    loc = str(job.get(\"location\", \"\")).lower().replace(\" \", \"\").replace(\",\", \"\")\n",
    "    tit_simple = title.replace(\" \", \"\")\n",
    "    unique_id = f\"{tit_simple}|{comp}|{loc}\"\n",
    "    if unique_id in seen_ids:\n",
    "        stats[\"excluded_duplicate\"] += 1\n",
    "        continue\n",
    "    seen_ids.add(unique_id)\n",
    "\n",
    "    # 3. SECTOR CLEANING\n",
    "    raw_sector = job.get(\"sector\")\n",
    "    if not raw_sector or str(raw_sector).strip() == \"\":\n",
    "        job['sector'] = \"Not Specified\"\n",
    "    else:\n",
    "        job['sector'] = str(raw_sector).strip()\n",
    "\n",
    "    # 4. GEOGRAPHIC PARSING (REWORKED)\n",
    "    job['city'] = None\n",
    "    job['region'] = None\n",
    "    job['country'] = None\n",
    "    \n",
    "    raw_loc = job.get(\"location\", \"\")\n",
    "    \n",
    "    if raw_loc:\n",
    "        parts = [p.strip() for p in raw_loc.split(',')]\n",
    "        \n",
    "        # LOGICA NOUƒÇ:\n",
    "        \n",
    "        # CAZ 3 ELEMENTE: \"City, Region, Country\"\n",
    "        if len(parts) >= 3:\n",
    "            job['city'] = parts[0]\n",
    "            job['region'] = \", \".join(parts[1:-1])\n",
    "            job['country'] = parts[-1].title()\n",
    "\n",
    "        # CAZ 2 ELEMENTE: \"City, Country\" (ex: \"Gloucester, United Kingdom\")\n",
    "        elif len(parts) == 2:\n",
    "            job['city'] = parts[0]\n",
    "            job['country'] = parts[1].title() # Al doilea element e »õara\n",
    "            \n",
    "        # CAZ 1 ELEMENT: \"Country\" SAU \"Metropolitan Area\" (ex: \"Stuttgart Region\")\n",
    "        elif len(parts) == 1:\n",
    "            candidate = parts[0]\n",
    "            # VerificƒÉm dacƒÉ e √Æn lista noastrƒÉ de corec»õii (Metropolitan Areas)\n",
    "            # Folosim o cƒÉutare par»õialƒÉ (dacƒÉ string-ul con»õine cheia) sau exactƒÉ\n",
    "            match_found = False\n",
    "            for region_key, correct_country in REGION_TO_COUNTRY_MAP.items():\n",
    "                if region_key.lower() in candidate.lower():\n",
    "                    job['country'] = correct_country\n",
    "                    job['region'] = candidate # PƒÉstrƒÉm originalul la regiune\n",
    "                    match_found = True\n",
    "                    break\n",
    "            \n",
    "            if not match_found:\n",
    "                # DacƒÉ nu e √Æn lista de corec»õii, presupunem cƒÉ e »öarƒÉ\n",
    "                job['country'] = candidate.title()\n",
    "\n",
    "    # CURƒÇ»öARE FINALƒÇ »öARƒÇ & ORA»ò\n",
    "    # 1. DacƒÉ »õara a rƒÉmas goalƒÉ, punem \"Unknown\"\n",
    "    if not job['country']:\n",
    "         job['country'] = \"Unknown\"\n",
    "         \n",
    "    # 2. DacƒÉ Ora»ôul == »öara (ex: \"United Kingdom, United Kingdom\"), »ôtergem ora»ôul\n",
    "    if job['city'] and job['country'] and job['city'].lower().strip() == job['country'].lower().strip():\n",
    "        job['city'] = None\n",
    "\n",
    "    # 5. LOCATION FIXES (From Locations.json)\n",
    "    if job.get('region') is None and job.get('location') in LOC_FIX_MAP:\n",
    "        fix_data = LOC_FIX_MAP[job['location']]\n",
    "        job['country'] = fix_data.get('country')\n",
    "        job['region'] = fix_data.get('region')\n",
    "        job['city'] = fix_data.get('city')\n",
    "\n",
    "    # 6. ROLE ASSIGNMENT\n",
    "    assigned_role = \"Uncategorized\"\n",
    "    extended_roles = {\n",
    "        \"Direct SOC Analyst\": [\"soc\", \"security analyst\", \"analyst\", \"operator\", \"monitoring\", \"intern\", \"student\", \"trainee\", \"junior\", \"graduate\", \"stage\", \"werkstudent\", \"watch\", \"handler\", \"analyste\", \"duales\", \"placement\", \"apprentice\"],\n",
    "        \"SOC Technology Specialists\": [\"engineer\", \"network\", \"system\", \"admin\", \"integrator\", \"architect\", \"support\", \"technician\", \"embedded\", \"infrastructure\", \"developer\", \"iam\", \"pki\", \"access\", \"identity\", \"cloud\", \"devops\", \"platform\", \"pentest\", \"hacker\", \"offensive\", \"vulnerability\", \"tester\", \"spezialist\", \"specialist\", \"expert\", \"sicherheit\", \"security professional\", \"engineer\", \"ingenieur\", \"product owner\", \"scientist\"],\n",
    "        \"Incident Response and Threat Intelligence\": [\"incident\", \"response\", \"threat\", \"intelligence\", \"forensic\", \"hunter\", \"cert\", \"csirt\", \"ir\", \"malware\", \"investigator\", \"crypto\"],\n",
    "        \"Sales, Management, Training & Consulting\": [\"manager\", \"head\", \"lead\", \"sales\", \"consultant\", \"trainer\", \"director\", \"coordinator\", \"officer\", \"ciso\", \"presales\", \"account\", \"risk\", \"compliance\", \"audit\", \"governance\", \"awareness\", \"legal\", \"advisor\", \"leiter\", \"vp\", \"vice president\", \"president\", \"professor\", \"lecturer\", \"teacher\", \"academic\", \"research\", \"advocate\", \"claims\"],\n",
    "        \"Cyber Defense and Operations\": [\"defense\", \"defence\", \"blue\", \"operations\", \"ops\", \"secops\", \"protect\", \"resilience\"]\n",
    "    }\n",
    "    match_found = False\n",
    "    for role_name, keywords in ROLES_DEF.items():\n",
    "        if any(k.lower() in title for k in keywords):\n",
    "            assigned_role = role_name\n",
    "            match_found = True\n",
    "            break\n",
    "    if not match_found:\n",
    "        for role_name, keywords in extended_roles.items():\n",
    "            if any(k in title for k in keywords):\n",
    "                assigned_role = role_name\n",
    "                break\n",
    "    job['role'] = assigned_role\n",
    "\n",
    "    # 7. SKILLS EXTRACTION\n",
    "    job_skills = {}\n",
    "    for category, skill_list in SKILLS_DEF.items():\n",
    "        found_skills = []\n",
    "        for skill in skill_list:\n",
    "            if re.search(r'\\b' + re.escape(skill) + r'\\b', desc, re.IGNORECASE):\n",
    "                found_skills.append(skill)\n",
    "        if found_skills:\n",
    "            job_skills[category] = found_skills\n",
    "    job['skills'] = job_skills\n",
    "\n",
    "    # FINAL ORDERING\n",
    "    ordered_job = {\n",
    "        \"title\": job.get(\"title\"),\n",
    "        \"companyName\": job.get(\"companyName\"),\n",
    "        \"location\": job.get(\"location\"),\n",
    "        \"country\": job.get(\"country\"),\n",
    "        \"region\": job.get(\"region\"),\n",
    "        \"city\": job.get(\"city\"),\n",
    "        \"jobUrl\": job.get(\"jobUrl\"),\n",
    "        \"contractType\": job.get(\"contractType\"),\n",
    "        \"sector\": job.get(\"sector\"),\n",
    "        \"experienceLevel\": job.get(\"experienceLevel\"),\n",
    "        \"companyUrl\": job.get(\"companyUrl\"),\n",
    "        \"description\": job.get(\"description\"),\n",
    "        \"source\": job.get(\"source\"),\n",
    "        \"role\": job.get(\"role\"),\n",
    "        \"skills\": job.get(\"skills\")\n",
    "    }\n",
    "\n",
    "    processed_jobs.append(ordered_job)\n",
    "\n",
    "stats[\"final_count\"] = len(processed_jobs)\n",
    "\n",
    "print(\"\\n--- FINAL EXECUTION REPORT ---\")\n",
    "print(f\"1. Total Jobs Scanned: {stats['total_read']}\")\n",
    "print(f\"2. Excluded (Irrelevant): -{stats['excluded_filter']}\")\n",
    "print(f\"3. Excluded (Duplicates): -{stats['excluded_duplicate']}\")\n",
    "print(f\"==========================================\")\n",
    "print(f\"‚úÖ FINAL DATASET FOR TABLEAU: {stats['final_count']} jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d53d07-7d49-4659-b4ca-6b3500164a9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5. CHECKING DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a28dd4-df26-4187-b779-1abe771b8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting Data Quality Check...\n",
      "\n",
      "--- üìä Job Role Distribution ---\n",
      "role\n",
      "SOC Technology Specialists                   1181\n",
      "Direct SOC Analyst                            743\n",
      "Sales, Management, Training & Consulting      201\n",
      "Uncategorized                                 116\n",
      "Incident Response and Threat Intelligence      76\n",
      "Cyber Defense and Operations                   20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- üé≤ Random Sample of 5 Jobs (Clean Data Preview) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>companyName</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>contractType</th>\n",
       "      <th>sector</th>\n",
       "      <th>experienceLevel</th>\n",
       "      <th>source</th>\n",
       "      <th>role</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>EXPERT SECURITE OPERATIONNELLE SI H/F</td>\n",
       "      <td>ICADE</td>\n",
       "      <td>Puteaux, √éle-de-France, France</td>\n",
       "      <td>France</td>\n",
       "      <td>√éle-de-France</td>\n",
       "      <td>Puteaux</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Associate</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>SOC Technology Specialists</td>\n",
       "      <td>{'Technical Skills': ['SIEM', 'EDR', 'CEH', 'C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>Senior Consultant - Technology Consulting - Cy...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Renens, Vaud, Switzerland</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Vaud</td>\n",
       "      <td>Renens</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Professional Services</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Sales, Management, Training &amp; Consulting</td>\n",
       "      <td>{'Programming languages': ['Go'], 'Ability': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>SOC Security Engineer (m/w/d)</td>\n",
       "      <td>Amprion GmbH</td>\n",
       "      <td>Pulheim, North Rhine-Westphalia, Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>North Rhine-Westphalia</td>\n",
       "      <td>Pulheim</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>SOC Technology Specialists</td>\n",
       "      <td>{'Ability': ['Deutsch', 'Berufserfahrung', 'En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>M≈Çodszy Specjalista ds. Cyberbezpiecze≈Ñstwa</td>\n",
       "      <td>Kuchnia Vikinga</td>\n",
       "      <td>Bia≈Çystok, Podlaskie, Poland</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Podlaskie</td>\n",
       "      <td>Bia≈Çystok</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Food and Beverage Manufacturing</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>{'Programming languages': ['PowerShell'], 'Tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Sr. Security Incident Handler</td>\n",
       "      <td>Databricks</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Direct SOC Analyst</td>\n",
       "      <td>{'Technical Skills': ['CISSP'], 'Soft Skills':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title      companyName  \\\n",
       "883               EXPERT SECURITE OPERATIONNELLE SI H/F            ICADE   \n",
       "1096  Senior Consultant - Technology Consulting - Cy...               EY   \n",
       "84                        SOC Security Engineer (m/w/d)     Amprion GmbH   \n",
       "1870        M≈Çodszy Specjalista ds. Cyberbezpiecze≈Ñstwa  Kuchnia Vikinga   \n",
       "309                       Sr. Security Incident Handler       Databricks   \n",
       "\n",
       "                                      location         country  \\\n",
       "883             Puteaux, √éle-de-France, France          France   \n",
       "1096                 Renens, Vaud, Switzerland     Switzerland   \n",
       "84    Pulheim, North Rhine-Westphalia, Germany         Germany   \n",
       "1870              Bia≈Çystok, Podlaskie, Poland          Poland   \n",
       "309            London, England, United Kingdom  United Kingdom   \n",
       "\n",
       "                      region       city contractType  \\\n",
       "883            √éle-de-France    Puteaux    Full-time   \n",
       "1096                    Vaud     Renens    Full-time   \n",
       "84    North Rhine-Westphalia    Pulheim    Full-time   \n",
       "1870               Podlaskie  Bia≈Çystok    Full-time   \n",
       "309                  England     London    Full-time   \n",
       "\n",
       "                               sector   experienceLevel    source  \\\n",
       "883                       Real Estate         Associate  LinkedIn   \n",
       "1096            Professional Services  Mid-Senior level  LinkedIn   \n",
       "84                          Utilities       Entry level  LinkedIn   \n",
       "1870  Food and Beverage Manufacturing       Entry level  LinkedIn   \n",
       "309              Software Development  Mid-Senior level  LinkedIn   \n",
       "\n",
       "                                          role  \\\n",
       "883                 SOC Technology Specialists   \n",
       "1096  Sales, Management, Training & Consulting   \n",
       "84                  SOC Technology Specialists   \n",
       "1870                             Uncategorized   \n",
       "309                         Direct SOC Analyst   \n",
       "\n",
       "                                                 skills  \n",
       "883   {'Technical Skills': ['SIEM', 'EDR', 'CEH', 'C...  \n",
       "1096  {'Programming languages': ['Go'], 'Ability': [...  \n",
       "84    {'Ability': ['Deutsch', 'Berufserfahrung', 'En...  \n",
       "1870  {'Programming languages': ['PowerShell'], 'Tec...  \n",
       "309   {'Technical Skills': ['CISSP'], 'Soft Skills':...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Data Check Complete. Total Records: 2337\n"
     ]
    }
   ],
   "source": [
    "# --- 5. CHECKING DATA SET (Quality Assurance) ---\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display # Import necessary for nice HTML tables\n",
    "\n",
    "print(\"üîç Starting Data Quality Check...\")\n",
    "\n",
    "# Convert the list of processed jobs into a Pandas DataFrame\n",
    "df = pd.DataFrame(processed_jobs)\n",
    "\n",
    "# 1. Analyze Job Role Distribution\n",
    "print(\"\\n--- üìä Job Role Distribution ---\")\n",
    "print(df['role'].value_counts())\n",
    "\n",
    "# 2. Visual Inspection (HTML Table)\n",
    "print(\"\\n--- üé≤ Random Sample of 5 Jobs (Clean Data Preview) ---\")\n",
    "\n",
    "# Setup generic pandas display options to ensure text isn't cut off too aggressively\n",
    "pd.set_option('display.max_colwidth', 50) \n",
    "\n",
    "# Create a clean view by dropping the heavy text columns just for this preview\n",
    "# We keep 'jobUrl' this time but truncate it via display options if needed, \n",
    "# or drop it if it's still too messy. Let's drop description/html for clarity.\n",
    "cols_to_hide = ['description', 'descriptionHtml', 'companyUrl', 'jobUrl']\n",
    "df_display = df.drop(columns=cols_to_hide, errors='ignore')\n",
    "\n",
    "# USE DISPLAY() INSTEAD OF PRINT()\n",
    "# This renders a beautiful HTML table in Jupyter Notebooks\n",
    "display(df_display.sample(5))\n",
    "\n",
    "print(f\"\\n‚úÖ Data Check Complete. Total Records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9159d42-8829-4d39-91c7-b1ee091157d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. FINAL EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16b0a35-5d7f-4ae3-8ed3-33ff80c1772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Success! The file 'SOC_Analyst_Master_Dataset.json' has been generated.\n",
      "This file is now ready for Tableau ingestion.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. FINAL EXPORT ---\n",
    "\n",
    "try:\n",
    "    with open(FINAL_OUTPUT, 'w', encoding='utf-8') as f:\n",
    "        json.dump(processed_jobs, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üéâ Success! The file '{FINAL_OUTPUT}' has been generated.\")\n",
    "    print(\"This file is now ready for Tableau ingestion.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
